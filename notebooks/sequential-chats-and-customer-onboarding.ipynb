{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "llm_config = {\"model\": \"gpt-4o\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martinfabbri/Workspace/github/graph-llm-agents/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_personal_information_agent = ConversableAgent(\n",
    "    name=\"Onboarding Personal Information Agent\",\n",
    "    system_message=\"\"\"You are a helpful customer onboarding agent,\n",
    "    you are here to help new customers get started with our product.\n",
    "    Your job is to gather customer's name and location.\n",
    "    Do not ask for other information. Return 'TERMINATE' \n",
    "    when you have gathered all the information.\"\"\",\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_topic_preference_agent = ConversableAgent(\n",
    "    name=\"Onboarding Topic preference Agent\",\n",
    "    system_message=\"\"\"You are a helpful customer onboarding agent,\n",
    "    you are here to help new customers get started with our product.\n",
    "    Your job is to gather customer's preferences on news topics.\n",
    "    Do not ask for other information.\n",
    "    Return 'TERMINATE' when you have gathered all the information.\"\"\",\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_engagement_agent = ConversableAgent(\n",
    "    name=\"Customer Engagement Agent\",\n",
    "    system_message=\"\"\"You are a helpful customer service agent\n",
    "    here to provide fun for the customer based on the user's\n",
    "    personal information and topic preferences.\n",
    "    This could include fun facts, jokes, or interesting stories.\n",
    "    Make sure to make it engaging and fun!\n",
    "    Return 'TERMINATE' when you are done.\"\"\",\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_proxy_agent = ConversableAgent(\n",
    "    name=\"customer_proxy_agent\",\n",
    "    llm_config=False,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats = [\n",
    "    {\n",
    "        \"sender\": onboarding_personal_information_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \n",
    "            \"Hello, I'm here to help you get started with our product.\"\n",
    "            \"Could you tell me your name and location?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"summary_args\": {\n",
    "            \"summary_prompt\" : \"Return the customer information \"\n",
    "                             \"into as JSON object only: \"\n",
    "                             \"{'name': '', 'location': ''}\",\n",
    "        },\n",
    "        \"max_turns\": 2,\n",
    "        \"clear_history\" : True\n",
    "    },\n",
    "    {\n",
    "        \"sender\": onboarding_topic_preference_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \n",
    "                \"Great! Could you tell me what topics you are \"\n",
    "                \"interested in reading about?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"max_turns\": 1,\n",
    "        \"clear_history\" : False\n",
    "    },\n",
    "    {\n",
    "        \"sender\": customer_proxy_agent,\n",
    "        \"recipient\": customer_engagement_agent,\n",
    "        \"message\": \"Let's find something fun to read.\",\n",
    "        \"max_turns\": 1,\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mOnboarding Personal Information Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Hello, I'm here to help you get started with our product.Could you tell me your name and location?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martinfabbri/Workspace/github/graph-llm-agents/.venv/lib/python3.12/site-packages/autogen/agentchat/chat.py:47: UserWarning: Repetitive recipients detected: The chat history will be cleared by default if a recipient appears more than once. To retain the chat history, please set 'clear_history=False' in the configuration of the repeating agent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding Personal Information Agent):\n",
      "\n",
      "Martin\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOnboarding Personal Information Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Thank you, Martin. Where are you located?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding Personal Information Agent):\n",
      "\n",
      "Eugene, OR\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mOnboarding Topic preference Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Great! Could you tell me what topics you are interested in reading about?\n",
      "Context: \n",
      "{\n",
      "  \"name\": \"Martin\",\n",
      "  \"location\": \"Eugene, OR\"\n",
      "}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding Topic preference Agent):\n",
      "\n",
      "Dogs\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Customer Engagement Agent):\n",
      "\n",
      "Let's find something fun to read.\n",
      "Context: \n",
      "{\n",
      "  \"name\": \"Martin\",\n",
      "  \"location\": \"Eugene, OR\"\n",
      "}\n",
      "Martin, from Eugene, OR, is interested in reading about dogs.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCustomer Engagement Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Hey Martin! Since youâ€™re from Eugene, OR, and you love dogs, here's a fun and engaging story about a dog that might brighten your day:\n",
      "\n",
      "**The Legend of Hachiko: The Loyal Dog**\n",
      "\n",
      "Have you ever heard of Hachiko? Hachiko was an Akita dog born in 1923 in Japan. His story is a testament to the unwavering loyalty of dogs. Owned by Professor Hidesaburo Ueno, Hachiko would walk to the Shibuya Train Station every day to greet his master upon his return from work.\n",
      "\n",
      "In May 1925, Professor Ueno unexpectedly passed away while at work and never returned to the station. Despite this tragedy, Hachiko continued to wait at the station every day for nearly 10 years, hoping to see his beloved owner again.\n",
      "\n",
      "Hachiko's dedication and loyalty deeply touched the hearts of the people in Tokyo. He became a symbol of ultimate devotion and resilience. A bronze statue of Hachiko was erected at Shibuya Station in his honor, and it stands there to this day, reminding everyone who passes by of the incredible bond between humans and dogs.\n",
      "\n",
      "**Fun Fact:**\n",
      "The statue of Hachiko at Shibuya Station is so famous that it's a popular meeting spot and has appeared in various movies and TV shows!\n",
      "\n",
      "What a heartwarming and inspiring tale, isn't it? Dogs truly are incredible companions!\n",
      "\n",
      "Hope you enjoyed this story, Martin. If you want more fun or heartwarming tales about dogs, just let me know!\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from autogen import initiate_chats\n",
    "\n",
    "chat_results = initiate_chats(chats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Martin\",\n",
      "  \"location\": \"Eugene, OR\"\n",
      "}\n",
      "\n",
      "\n",
      "Martin, from Eugene, OR, is interested in reading about dogs.\n",
      "\n",
      "\n",
      "Martin, from Eugene, OR, has an interest in dogs and enjoyed reading the heartwarming story of Hachiko, an Akita dog known for his unwavering loyalty in awaiting his owner daily at Shibuya Train Station even after the owner's unexpected death. This story highlights the incredible bond between humans and dogs, symbolized by a statue of Hachiko at Shibuya Station.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_result in chat_results:\n",
    "    print(chat_result.summary)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_including_cached_inference': {'total_cost': 0.001325, 'gpt-4o-2024-05-13': {'cost': 0.001325, 'prompt_tokens': 175, 'completion_tokens': 30, 'total_tokens': 205}}, 'usage_excluding_cached_inference': {'total_cost': 0.001325, 'gpt-4o-2024-05-13': {'cost': 0.001325, 'prompt_tokens': 175, 'completion_tokens': 30, 'total_tokens': 205}}}\n",
      "\n",
      "\n",
      "{'usage_including_cached_inference': {'total_cost': 0.0005600000000000001, 'gpt-4o-2024-05-13': {'cost': 0.0005600000000000001, 'prompt_tokens': 70, 'completion_tokens': 14, 'total_tokens': 84}}, 'usage_excluding_cached_inference': {'total_cost': 0.0005600000000000001, 'gpt-4o-2024-05-13': {'cost': 0.0005600000000000001, 'prompt_tokens': 70, 'completion_tokens': 14, 'total_tokens': 84}}}\n",
      "\n",
      "\n",
      "{'usage_including_cached_inference': {'total_cost': 0.00836, 'gpt-4o-2024-05-13': {'cost': 0.00836, 'prompt_tokens': 505, 'completion_tokens': 389, 'total_tokens': 894}}, 'usage_excluding_cached_inference': {'total_cost': 0.00836, 'gpt-4o-2024-05-13': {'cost': 0.00836, 'prompt_tokens': 505, 'completion_tokens': 389, 'total_tokens': 894}}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_result in chat_results:\n",
    "    print(chat_result.cost)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
