{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raven_post(payload):\n",
    "    \"\"\"\n",
    "    Sends a payload to a TGI endpoint.\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    # Specify the LLM Endpoint\n",
    "    # Now, let's prompt Raven!\n",
    "    API_URL = \"http://nexusraven.nexusflow.ai\"\n",
    "    headers = {\n",
    "            \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "def query_raven(prompt):\n",
    "    \"\"\"\n",
    "    This function sends a request to the TGI endpoint to get Raven's function call.\n",
    "    This will not generate Raven's justification and reasoning for the call, to save on latency.\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    output = raven_post({\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\" : {\"temperature\" : 0.001, \"stop\" : [\"<bot_end>\"], \"do_sample\" : False, \"max_new_tokens\" : 2048, \"return_full_text\" : False}})\n",
    "    call = output[0][\"generated_text\"].replace(\"Call:\", \"\").strip()\n",
    "    return call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "John Doe lives at 123 Elm Street, Springfield. Next to him is Jane Smith, residing at 456 Oak Avenue, Lakeview. Not far away, we find Dr. Emily Ryan at 789 Pine Road, Westwood. Meanwhile, in a different part of town, Mr. Alan Turing can be found at 101 Binary Blvd, Computerville. Nearby, Ms. Olivia Newton stays at 202 Music Lane, Harmony. Also, Prof. Charles Xavier is located at 505 Mutant Circle, X-Town.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \\\n",
    "\"\"\"\n",
    "John Doe lives at 123 Elm Street, Springfield. Next to him is Jane Smith, residing at 456 Oak Avenue, Lakeview. Not far away, we find Dr. Emily Ryan at 789 Pine Road, Westwood. Meanwhile, in a different part of town, Mr. Alan Turing can be found at 101 Binary Blvd, Computerville. Nearby, Ms. Olivia Newton stays at 202 Music Lane, Harmony. Also, Prof. Charles Xavier is located at 505 Mutant Circle, X-Town.\n",
    "\"\"\"\n",
    "print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raven_prompt = f'''\n",
    "Function:\n",
    "def address_name_pairs(names : list[str], addresses : list[str]):\n",
    "\"\"\"\n",
    "Give names and associated addresses.\n",
    "\"\"\"\n",
    "\n",
    "{text}<human_end>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Doe :  123 Elm Street, Springfield\n",
      "Jane Smith :  456 Oak Avenue, Lakeview\n",
      "Dr. Emily Ryan :  789 Pine Road, Westwood\n",
      "Mr. Alan Turing :  101 Binary Blvd, Computerville\n",
      "Ms. Olivia Newton :  202 Music Lane, Harmony\n",
      "Prof. Charles Xavier :  505 Mutant Circle, X-Town\n"
     ]
    }
   ],
   "source": [
    "def address_name_pairs(names : list[str], addresses : list[str]):\n",
    "  \"\"\"\n",
    "  Give names and associated addresses.\n",
    "  \"\"\"\n",
    "  for name, addr in zip(names, addresses):\n",
    "    print (name, \": \", addr)\n",
    "\n",
    "result = query_raven(raven_prompt)\n",
    "eval(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chin-Yew Lin : ROUGE: A package for automatic evaluation of summaries 2004\n",
      "Association for Computational Linguistics : Useridentifier: Implicit user representations for simple and effective personalized sentiment analysis 2022\n",
      "Fatemehsadat Mireshghallah : Cross-task generalization via natural language crowdsourcing instructions 2022\n",
      "Vaishnavi Shrivastava : Learning to compress prompts with gist tokens 2023\n",
      "Milad Shokouhi : Sentence-t5: Scalable sentence encoders from pre-trained text-to-text models 2022\n",
      "Taylor Berg-Kirkpatrick : GPT-4 technical report 2023\n",
      "Robert Sim : Training language models to follow instructions with human feedback 2022\n"
     ]
    }
   ],
   "source": [
    "text = \\\n",
    "\"\"\"\n",
    "Chin-Yew Lin. 2004. ROUGE: A package for automatic evaluation of summaries. In Text Summarization Branches Out, pages 74–81, Barcelona, Spain.\n",
    "Association for Computational Linguistics.\n",
    "Fatemehsadat Mireshghallah, Vaishnavi Shrivastava,\n",
    "Milad Shokouhi, Taylor Berg-Kirkpatrick, Robert\n",
    "Sim, and Dimitrios Dimitriadis. 2022. Useridentifier:\n",
    "Implicit user representations for simple and effective\n",
    "personalized sentiment analysis. In Proceedings of\n",
    "the 2022 Conference of the North American Chapter\n",
    "of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022, Seattle,\n",
    "WA, United States, July 10-15, 2022, pages 3449–\n",
    "3456. Association for Computational Linguistics.\n",
    "Swaroop Mishra, Daniel Khashabi, Chitta Baral, and\n",
    "Hannaneh Hajishirzi. 2022. Cross-task generalization via natural language crowdsourcing instructions.\n",
    "In Proceedings of the 60th Annual Meeting of the\n",
    "Association for Computational Linguistics (Volume\n",
    "1: Long Papers), ACL 2022, Dublin, Ireland, May\n",
    "22-27, 2022, pages 3470–3487. Association for Computational Linguistics.\n",
    "Jesse Mu, Xiang Lisa Li, and Noah Goodman. 2023.\n",
    "Learning to compress prompts with gist tokens.\n",
    "Jianmo Ni, Gustavo Hernández Ábrego, Noah Constant,\n",
    "Ji Ma, Keith B. Hall, Daniel Cer, and Yinfei Yang.\n",
    "2022. Sentence-t5: Scalable sentence encoders from\n",
    "pre-trained text-to-text models. In Findings of the Association for Computational Linguistics: ACL 2022,\n",
    "Dublin, Ireland, May 22-27, 2022, pages 1864–1874.\n",
    "Association for Computational Linguistics.\n",
    "OpenAI. 2023. GPT-4 technical report. CoRR,\n",
    "abs/2303.08774.\n",
    "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\n",
    "Carroll L. Wainwright, Pamela Mishkin, Chong\n",
    "Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray,\n",
    "John Schulman, Jacob Hilton, Fraser Kelton, Luke\n",
    "Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe.\n",
    "2022. Training language models to follow instructions with human feedback. In NeurIPS.\n",
    "Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the\n",
    "40th Annual Meeting of the Association for Computational Linguistics, July 6-12, 2002, Philadelphia,\n",
    "PA, USA, pages 311–318. ACL.\n",
    "\"\"\"\n",
    "\n",
    "def paper_and_authors_pairs(authors : list[str], papers : list[str], years: list[int]):\n",
    "  \"\"\"\n",
    "  Associates papers with their respective authors.\n",
    "  \"\"\"\n",
    "  for author, paper, year in zip(authors, papers, years):\n",
    "    print (f\"{author} : {paper} {year}\")\n",
    "\n",
    "raven_prompt = f\"\"\"\n",
    "Function:\n",
    "def paper_and_authors_pairs(authors : list[str], papers : list[str], years: list[int]):\n",
    "'''\n",
    "Tuples of main author, paper and year.\n",
    "'''\n",
    "\n",
    "{text}<human_end>\n",
    "\"\"\"\n",
    "\n",
    "result = query_raven(raven_prompt)\n",
    "eval(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dr. Susan Hill has a practice at 120 Green Road, Evergreen City, and also consults at 450 Riverdale Drive, Brookside. Mark Twain, the renowned author, once lived at 300 Maple Street, Springfield, but now resides at 200 Writers Block, Literaryville. The famous artist, Emily Carter, showcases her work at 789 Artisan Alley, Paintown, and has a studio at 101 Palette Place, Creativeland. Meanwhile, the tech innovator, John Tech, has his main office at 555 Silicon Street, Techville, and a secondary office at 777 Data Drive, Computown, but he lives at 123 Digital Domain, Innovatown.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unbalanced_text = \\\n",
    "\"\"\"\n",
    "Dr. Susan Hill has a practice at 120 Green Road, Evergreen City, and also consults at 450 Riverdale Drive, Brookside. Mark Twain, the renowned author, once lived at 300 Maple Street, Springfield, but now resides at 200 Writers Block, Literaryville. The famous artist, Emily Carter, showcases her work at 789 Artisan Alley, Paintown, and has a studio at 101 Palette Place, Creativeland. Meanwhile, the tech innovator, John Tech, has his main office at 555 Silicon Street, Techville, and a secondary office at 777 Data Drive, Computown, but he lives at 123 Digital Domain, Innovatown.\n",
    "\"\"\"\n",
    "print (unbalanced_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert_into_database(names=[Record(name='Dr. Susan Hill', addresses=['120 Green Road', '450 Riverdale Drive']), Record(name='Mark Twain', addresses=['300 Maple Street', '200 Writers Block']), Record(name='Emily Carter', addresses=['789 Artisan Alley', '101 Palette Place']), Record(name='John Tech', addresses=['555 Silicon Street', '777 Data Drive', '123 Digital Domain'])])\n"
     ]
    }
   ],
   "source": [
    "raven_prompt = \\\n",
    "f'''\n",
    "\n",
    "@dataclass\n",
    "class Record:\n",
    "    name : str\n",
    "    addresses : List[str]\n",
    "\n",
    "Function:\n",
    "def insert_into_database(names : List[Record]):\n",
    "\"\"\"\n",
    "Inserts the records into the database. \n",
    "\"\"\"\n",
    "\n",
    "{unbalanced_text}<human_end>\n",
    "\n",
    "'''\n",
    "\n",
    "result = query_raven(raven_prompt)\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert_into_database(authors=[Record(authors='Glänzel & Schubert', year=[2003]), Record(authors='Leydesdorff & Bornmann', year=[2011]), Record(authors='Nielsen & Andersen', year=[2021]), Record(authors='Petersen, Pan et al.', year=[2019]), Record(authors='Waltman & van Eck', year=[2019])])\n"
     ]
    }
   ],
   "source": [
    "text = \\\n",
    "\"\"\"\n",
    "Bibliometric research has often relied on an argument of random errors, which are assumed to even out when the lens is shifted from the individual object (where one may find missing and erroneous citations and references, or deliberate differences in the intentions of a reference (e.g., criticism)) to the statistical aggregate (Van Raan, 1998). This is a meaningful approach, but it requires that the objects that are aggregated are more or less the same type of objects. Naïvely, we could assume that scientific publications are all the same; however, it is well established that there are rather large differences in, for example, referencing practices between fields (Glänzel & Schubert, 2003; Leydesdorff & Bornmann, 2011). This makes direct comparisons of citation counts and averages between fields somewhat meaningless. One might even argue that unstable changes even make comparisons within fields somewhat meaningless over longer time spans, whether those changes are due to changes in database inclusion or an absolute change in publication intensity (Nielsen & Andersen, 2021; Petersen, Pan et al., 2019). This is not new, and sophisticated indicators have been developed to account for some of these field differences in citation impact (Waltman & van Eck, 2019).\n",
    "\"\"\"\n",
    "\n",
    "raven_prompt = \\\n",
    "f'''\n",
    "\n",
    "@dataclass\n",
    "class Record:\n",
    "    \"\"\"pair of references including authors and the publication year, authors can be associated with multiple years.\"\"\"\n",
    "    authors : str # authors referenced in the text\n",
    "    year : List[int]         # year of publication\n",
    "\n",
    "Function:\n",
    "def insert_into_database(authors : List[Record]):\n",
    "\"\"\"\n",
    "Inserts the records into the database. \n",
    "\"\"\"\n",
    "\n",
    "{text}<human_end>\n",
    "\n",
    "'''\n",
    "\n",
    "result = query_raven(raven_prompt)\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Valid JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\n",
    "  \"city_name\" : \"London\"\n",
    "  \"location\" : {\n",
    "      \"country\" : \"United Kingdom\",\n",
    "      \"continent\" : {\n",
    "          \"simple_name\" : \"Europe\",\n",
    "          \"other_name\" : \"Afro-Eur-Asia\"\n",
    "      }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_info(city_name : str, location : dict):\n",
    "  \"\"\"\n",
    "  Gets the city info\n",
    "  \"\"\"\n",
    "  return locals()\n",
    "def construct_location_dict(country : str, continent : dict):\n",
    "  \"\"\"\n",
    "  Provides the location dictionary\n",
    "  \"\"\"\n",
    "  return locals()\n",
    "def construct_continent_dict(simple_name : str, other_name : str):\n",
    "  \"\"\"\n",
    "  Provides the continent dict\n",
    "  \"\"\"\n",
    "  return locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city_name': 'London', 'location': {}}\n"
     ]
    }
   ],
   "source": [
    "print (city_info(\"London\", {}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "raven_prompt = \\\n",
    "'''\n",
    "Function:\n",
    "def city_info(city_name : str, location : dict):\n",
    "\"\"\"\n",
    "Gets the city info\n",
    "\"\"\"\n",
    "\n",
    "Function:\n",
    "def construct_location_dict(country : str, continent : dict):\n",
    "\"\"\"\n",
    "Provides the location dictionary\n",
    "\"\"\"\n",
    "\n",
    "def construct_continent_dict(simple_name : str, other_name : str):\n",
    "\"\"\"\n",
    "Provides the continent dict\n",
    "\"\"\"\n",
    "\n",
    "User Query: {question}<human_end>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city_name': 'London', 'location': {'country': 'United Kingdom', 'continent': {'simple_name': 'Europe', 'other_name': 'Afro-Eur-Asia'}}}\n"
     ]
    }
   ],
   "source": [
    "question = \"I want the city info for London, \"\\\n",
    "\"which is in the United Kingdom, which is in Europe or Afro-Eur-Asia.\"\n",
    "\n",
    "output = query_raven(raven_prompt.format(question = question))\n",
    "json0 = eval(output)\n",
    "print (json0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"city_name\": \"London\", \"location\": {\"country\": \"United Kingdom\", \"continent\": {\"simple_name\": \"Europe\", \"other_name\": \"Afro-Eur-Asia\"}}}'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps(json0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city_name': 'Tokyo', 'location': {'country': 'Japan', 'continent': {'simple_name': 'Asian', 'other_name': 'Eurasia'}}}\n"
     ]
    }
   ],
   "source": [
    "question = \"I need details for the city of Tokyo, \"\\\n",
    "\"situated in Japan, a part of the Asian continent, \"\\\n",
    "\"which is sometimes referred to as Eurasia.\"\n",
    "\n",
    "output = query_raven(raven_prompt.format(question = question))\n",
    "json1 = eval(output)\n",
    "print (json1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"city_name\": \"London\", \"location\": {\"country\": \"United Kingdom\", \"continent\": {\"simple_name\": \"Europe\", \"other_name\": \"Afro-Eur-Asia\"}}}'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps(json0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
