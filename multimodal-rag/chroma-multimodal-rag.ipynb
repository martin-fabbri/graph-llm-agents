{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction\n",
    "from chromadb.utils.data_loaders import ImageLoader\n",
    "\n",
    "embedding_function = OpenCLIPEmbeddingFunction()\n",
    "image_loader = ImageLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "\n",
    "vehicles = client.create_collection(\n",
    "    name=\"vehicle_images\",\n",
    "    embedding_function=embedding_function,\n",
    "    data_loader=image_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images added to collection.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_paths = []\n",
    "image_ids = []\n",
    "dataset_folder = \"dataset/\"\n",
    "\n",
    "for image_folder in os.listdir(dataset_folder):\n",
    "    folder_path = os.path.join(dataset_folder, image_folder)\n",
    "    for filename in sorted(os.listdir(folder_path)):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            image_paths.append(os.path.join(folder_path, filename))\n",
    "            image_ids.append(f\"{image_folder}-{filename.split(\".\")[0]}\")\n",
    "\n",
    "vehicles.add(ids=image_ids, uris=image_paths)\n",
    "print(\"Images added to collection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve images based on description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/truck/Image_71.jpg\n"
     ]
    }
   ],
   "source": [
    "retrieved = vehicles.query(query_texts=[\"old red truck\"], n_results=1, include=[\"uris\"])\n",
    "\n",
    "for uri in retrieved[\"uris\"][0]:\n",
    "    try:\n",
    "        print(uri)\n",
    "    except AttributeError:\n",
    "        print(f\"Could not load image from {uri}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chat_openai = ChatOpenAI(model=\"gpt-4o\", temperature=\"0.0\")\n",
    "# Instantiate the Output Parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Define the Prompt\n",
    "image_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful car showroom assistant. Answer the user's question  using the given image context with direct references to parts of the images provided.\"\n",
    "            \" Highlight the pros and cons of each vehicle. Use markdown formatting for highlights, emphasis, and structure.\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            [\n",
    "                {\"type\": \"text\", \"text\": \"I'm interested in buying a {user_query}\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": \"data:image/jpeg;base64,{image_data_1}\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": \"data:image/jpeg;base64,{image_data_2}\",\n",
    "                },\n",
    "            ],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the LangChain Chain\n",
    "vision_chain = image_prompt | chat_openai | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to query a database, taking a query string and an optional number of results to return.\n",
    "def query_db(query, results=1):\n",
    "    # Use the vehicles database's query method to search for data matching the query.\n",
    "    # It fetches a specified number of results and includes URIs in the returned data.\n",
    "    results = vehicles.query(\n",
    "        query_texts=[query],\n",
    "        n_results=results,\n",
    "        include=['uris'])\n",
    "    # Return the search results.\n",
    "    return results\n",
    "\n",
    "# Define a function to display the results from a database query.\n",
    "def print_results(results):\n",
    "    # Iterate over each URI in the first list of URIs contained in the results dictionary.\n",
    "    # This assumes that results are structured with 'uris' as a key pointing to a list of lists of URIs.\n",
    "    for uri in results['uris'][0]:\n",
    "        # Print the file path of the URI to the console.\n",
    "        print(f\"Path: {uri}\")\n",
    "        # Display the image using the IPython display function, setting the image width to 300 pixels for better visibility.\n",
    "        display(Image(filename=uri, width=300))\n",
    "        # Print a newline to ensure separation between consecutive images for clarity.\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# To start things off, run this block of code\n",
    "#\n",
    "\n",
    "query = \"cheap blue car\"\n",
    "\n",
    "# bring back the first two images that match our query\n",
    "# then call our chain\n",
    "#\n",
    "results = query_db(query, results=2)\n",
    "prompt_input = format_prompt_inputs(results, query)\n",
    "response = image_chain.invoke(prompt_input)\n",
    "\n",
    "# Show the images used\n",
    "display(Markdown(\"Example Picture 1:\"))\n",
    "display(Image(filename=results['uris'][0][0], width=300))\n",
    "display(Markdown(\"Example Picture 2:\"))\n",
    "display(Image(filename=results['uris'][0][1], width=300))\n",
    "\n",
    "# Printing LLM Response\n",
    "display(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
